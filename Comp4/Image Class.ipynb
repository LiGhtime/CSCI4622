{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline  \n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","data = np.load('/kaggle/input/cuboulder-image-labelling/train_and_test.npz')\n","X_train, y_train, X_test = data['X_train'], data['y_train'], data['X_test']"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["def show(point, class_name=None, ax=plt):\n","    ax.imshow(point)\n","    if ax == plt:\n","        ax.xticks([])\n","        ax.yticks([])\n","    else:\n","        ax.set_title('class: %s' % class_name)\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","\n","def show_tile(points, labels, w, h, start=0):\n","    fig, axs = plt.subplots(w, h, figsize=(20,20))\n","    for i, point in enumerate([(x,y) for x in range(0, w) for y in range(0,h)]):\n","        show(points[i + start], labels[i + start], axs[point])\n","\n","show_tile(X_train, y_train, 10, 6)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# detecting circles with opencv \n","# modified from https://www.geeksforgeeks.org/circle-detection-using-opencv-python/\n","import cv2 \n","\n","\n","def blur(img):\n","    return cv2.blur(img, (3,3))\n","\n","\n","def gray(img):\n","    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","\n","def circles(img, draw_on_image=False):\n","    gray_blurred = blur(gray(img))\n","    \n","    detected_circles = None\n","    \n","    min_thresh = 20\n","    while min_thresh > 1 and detected_circles is None:\n","        min_thresh -= 1\n","        detected_circles = cv2.HoughCircles(gray_blurred, \n","                                            method=cv2.HOUGH_GRADIENT, \n","                                            dp=1, \n","                                            minDist=20, \n","                                            param1=20,\n","                                            param2=min_thresh,\n","                                            minRadius=7,\n","                                            maxRadius=30) \n","    # Convert the circle parameters a, b and r to integers. \n","    detected_circles = np.uint16(np.around(detected_circles)) \n","    if draw_on_image:\n","        out = img.copy()\n","        for pt in detected_circles[0, :]: \n","            a, b, r = pt[0], pt[1], pt[2] \n","\n","            # Draw the circumference of the circle. \n","            cv2.circle(out, (a, b), r, (0, 255, 0), 2) \n","\n","            # Draw a small circle (of radius 1) to show the center. \n","            cv2.circle(out, (a, b), 1, (0, 0, 255), 3) \n","        return out\n","    else:\n","        return detected_circles[0][0]\n","\n","    \n","# https://stackoverflow.com/a/47629363/2821370\n","def background_subtract_circle(img, circle):\n","    x,y,r = circle\n","    mask = np.zeros_like(img[:,:,:])\n","    cv2.circle(mask, (x,y), r, (255,255,255), -1, 8, 0)\n","    out = img&mask\n","    return out\n","\n","def crop_image(img):\n","    return background_subtract_circle(img, circles(img))\n","\n","point = X_train[700]\n","\n","#plt.imshow(circles(point, True), cmap='gray', vmin=0, vmax=255)\n","#plt.imshow(edges(point), cmap='gray', vmin=0, vmax=255)\n","\n","X_train_cropped = [gray(crop_image(img)) for img in X_train]\n","plt.imshow(X_train_cropped[700], cmap='gray', vmin=0, vmax=255);"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["plt.figure(figsize=(20, 5))\n","vals = len(np.unique(y_train))\n","plt.hist(y_train, bins=range(0,vals))\n","plt.xticks(range(0, vals));"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n","# https://keras.io/getting-started/functional-api-guide/\n","from keras.layers import Input, Dense\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras.models import Model\n","\n","input_img = Input(shape=(32, 32, 1))\n","\n","output_1 = Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')(input_img)\n","output_1_pool = MaxPooling2D((2,2))(output_1)\n","\n","output_2 = Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')(output_1_pool)\n","output_pool = MaxPooling2D((3,3))(output_2)\n","\n","img_output = Flatten()(output_pool)\n","\n","digits_1 = Dense(64, activation='relu')(img_output)\n","digits_2 = Dropout(0.1)(digits_1)\n","digits_3 = Dense(64, activation='relu')(digits_2)\n","\n","digits_output = Dense(43, activation='softmax')(digits_3)\n","\n","model = Model(inputs=input_img, outputs=digits_output)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","xtrain, xtest, ytrain, ytest = train_test_split(X_train_cropped, y_train, test_size=0.2)\n","ytrain = to_categorical(ytrain)\n","ytest = to_categorical(ytest)\n","\n","xtrain = np.array(xtrain)\n","xtest = np.array(xtest)\n","ytrain = np.array(ytrain)\n","ytest = np.array(ytest)\n","\n","xtrain = xtrain.reshape(xtrain.shape[0], 32, 32, 1)\n","xtest = xtest.reshape(xtest.shape[0], 32, 32, 1)\n","\n","batch_size = 16\n","\n","# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n","# this is the augmentation configuration we will use for training\n","train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=False)\n","\n","# this is the augmentation configuration we will use for testing:\n","# only rescaling\n","test_datagen = ImageDataGenerator(rescale=1./255)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["model.fit_generator(\n","    train_datagen.flow(xtrain, ytrain, batch_size=32), \n","    #steps_per_epoch=len(xtrain) / 32,\n","    validation_data=test_datagen.flow(xtest, ytest, batch_size=32),\n","    epochs=200)\n","\n","# model.fit(xtrain, ytrain,\n","#           epochs=200,\n","#           batch_size=16,\n","#           validation_data=(xtest, ytest))\n","# model.save_weights('model.h5')"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.7.4-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}